import os
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from torchvision import transforms
import argparse
from tqdm import tqdm
from change_detection.CWCD.backbone import build_backbone
import random
import time

class DomainVisualizer:
    def __init__(self, dataset_path, model_name='hrnet'):
        """
        åˆå§‹åŒ–åŸŸå¯è§†åŒ–å™¨
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„
            model_name: éª¨å¹²ç½‘ç»œåç§°
        """
        self.dataset_path = dataset_path
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ„å»ºHRNetéª¨å¹²ç½‘ç»œ
        self.backbone, self.num_stages, _ = build_backbone(model_name=model_name)
        self.backbone = self.backbone.to(self.device)
        self.backbone.eval()
        
        # ç®€å•çš„å½’ä¸€åŒ–é¢„å¤„ç†ï¼ˆä¸åŠ ä»»ä½•æ•°æ®å¢å¼ºï¼‰
        self.transform = transforms.Compose([
            transforms.Resize((256, 256)),  # è°ƒæ•´åˆ°å›ºå®šå¤§å°
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        print(f"Model loaded on {self.device}")
        print(f"Number of stages: {self.num_stages}")

    def load_dataset_paths(self, split='train', max_samples=None):
        """
        åŠ è½½æ•°æ®é›†è·¯å¾„
        
        Args:
            split: æ•°æ®é›†åˆ†å‰² ('train', 'val', 'test')
            max_samples: æœ€å¤§æ ·æœ¬æ•°é‡ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æ ·æœ¬
        
        Returns:
            List of (pathA, pathB) tuples
        """
        txt_path = os.path.join(self.dataset_path, f'{split}.txt')
        
        if not os.path.exists(txt_path):
            raise FileNotFoundError(f"Dataset file not found: {txt_path}")
        
        with open(txt_path, 'r') as f:
            lines = f.readlines()
        
        paths = []
        for line in lines:
            parts = line.strip().split('  ')
            if len(parts) >= 2:
                pathA, pathB = parts[0], parts[1]
                paths.append((pathA, pathB))
        
        total_samples = len(paths)
        print(f"Found {total_samples} image pairs in {split} set")
        
        # å¦‚æœæŒ‡å®šäº†max_samplesï¼Œåˆ™éšæœºé‡‡æ ·
        if max_samples is not None and max_samples < total_samples:
            paths = random.sample(paths, max_samples)
            print(f"Randomly sampled {max_samples} pairs from {total_samples} total pairs")
        else:
            print(f"Using all {total_samples} image pairs")
        
        return paths

    def extract_features(self, image_paths, batch_size=32):
        """
        æå–å›¾åƒç‰¹å¾
        
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
        
        Returns:
            features: æå–çš„ç‰¹å¾ (N, feature_dim)
            labels: æ ‡ç­¾ (0è¡¨ç¤ºæ—¶ç›¸Aï¼Œ1è¡¨ç¤ºæ—¶ç›¸B)
        """
        features_list = []
        labels_list = []
        
        # å‡†å¤‡æ‰€æœ‰å›¾åƒè·¯å¾„å’Œå¯¹åº”æ ‡ç­¾
        all_paths = []
        all_labels = []
        
        for pathA, pathB in image_paths:
            all_paths.extend([pathA, pathB])
            all_labels.extend([0, 1])  # 0=æ—¶ç›¸A, 1=æ—¶ç›¸B
        
        total_images = len(all_paths)
        print(f"Processing {total_images} images ({total_images//2} image pairs)...")
        
        # æ‰¹å¤„ç†æå–ç‰¹å¾
        processed_count = 0
        failed_count = 0
        
        for i in tqdm(range(0, total_images, batch_size), desc="Extracting features"):
            batch_paths = all_paths[i:i+batch_size]
            batch_labels = all_labels[i:i+batch_size]
            
            batch_images = []
            valid_labels = []
            
            for j, img_path in enumerate(batch_paths):
                try:
                    # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
                    img = Image.open(img_path).convert('RGB')
                    img_tensor = self.transform(img)
                    batch_images.append(img_tensor)
                    valid_labels.append(batch_labels[j])
                    processed_count += 1
                except Exception as e:
                    print(f"Error loading {img_path}: {e}")
                    failed_count += 1
                    continue
            
            if not batch_images:
                continue
            
            # è½¬æ¢ä¸ºbatch tensor
            batch_tensor = torch.stack(batch_images).to(self.device)
            
            # æå–ç‰¹å¾
            with torch.no_grad():
                backbone_features = self.backbone(batch_tensor)
                # é€‰æ‹©ç¬¬å››å±‚ç‰¹å¾ï¼ˆå€’æ•°ç¬¬ä¸€å±‚ï¼‰
                if isinstance(backbone_features, (list, tuple)):
                    target_features = backbone_features[-1]  # æœ€åä¸€å±‚
                else:
                    target_features = backbone_features
                
                # å…¨å±€å¹³å‡æ± åŒ–
                if len(target_features.shape) == 4:  # (B, C, H, W)
                    pooled_features = torch.nn.functional.adaptive_avg_pool2d(target_features, (1, 1))
                    pooled_features = pooled_features.view(pooled_features.size(0), -1)
                else:
                    pooled_features = target_features
                
                features_list.append(pooled_features.cpu().numpy())
                labels_list.extend(valid_labels)
        
        print(f"Successfully processed: {processed_count} images")
        print(f"Failed to process: {failed_count} images")
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        if features_list:
            features = np.vstack(features_list)
            labels = np.array(labels_list)
            print(f"Final extracted features shape: {features.shape}")
            print(f"Phase A samples: {np.sum(labels == 0)}")
            print(f"Phase B samples: {np.sum(labels == 1)}")
            return features, labels
        else:
            raise RuntimeError("No features were extracted successfully")

    def perform_pca_with_progress(self, features, n_components, random_state=42):
        """
        æ‰§è¡ŒPCAé™ç»´å¹¶æ˜¾ç¤ºè¿›åº¦æ¡
        
        Args:
            features: ç‰¹å¾çŸ©é˜µ
            n_components: ä¸»æˆåˆ†æ•°é‡
            random_state: éšæœºç§å­
        
        Returns:
            reduced_features: é™ç»´åçš„ç‰¹å¾
            pca: PCAå¯¹è±¡
        """
        print(f"ğŸ”„ Performing PCA to {n_components} dimensions...")
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(total=100, desc="PCA Progress", unit="%")
        
        try:
            # å¼€å§‹PCA
            pbar.set_description("PCA: Initializing")
            pbar.update(10)
            
            pca = PCA(n_components=n_components, random_state=random_state)
            
            pbar.set_description("PCA: Computing SVD")
            pbar.update(30)
            
            # æ‰§è¡ŒPCAæ‹Ÿåˆå’Œå˜æ¢
            reduced_features = pca.fit_transform(features)
            
            pbar.set_description("PCA: Finalizing")
            pbar.update(60)
            
            # å®Œæˆ
            pbar.set_description("PCA: Completed")
            pbar.update(100)
            pbar.close()
            
            print(f"âœ… PCA completed successfully!")
            print(f"   - Input shape: {features.shape}")
            print(f"   - Output shape: {reduced_features.shape}")
            print(f"   - Explained variance ratio (first 10): {pca.explained_variance_ratio_[:min(10, len(pca.explained_variance_ratio_))]}")
            
            return reduced_features, pca
            
        except Exception as e:
            pbar.close()
            print(f"âŒ PCA failed: {e}")
            raise

    def perform_tsne_with_progress(self, features, perplexity=30, n_iter=1000, random_state=42):
        """
        æ‰§è¡Œt-SNEé™ç»´å¹¶æ˜¾ç¤ºè¿›åº¦æ¡
        
        Args:
            features: ç‰¹å¾çŸ©é˜µ
            perplexity: t-SNEå‚æ•°
            n_iter: è¿­ä»£æ¬¡æ•°
            random_state: éšæœºç§å­
        
        Returns:
            reduced_features: é™ç»´åçš„ç‰¹å¾
        """
        print(f"ğŸ”„ Performing t-SNE (perplexity={perplexity}, n_iter={n_iter})...")
        
        # è°ƒæ•´perplexityä»¥é€‚åº”æ•°æ®å¤§å°
        max_perplexity = min(perplexity, (features.shape[0] - 1) // 3)
        if max_perplexity < perplexity:
            print(f"âš ï¸  Adjusting perplexity from {perplexity} to {max_perplexity} due to sample size")
            perplexity = max_perplexity
        
        # åˆ›å»ºè‡ªå®šä¹‰çš„t-SNEç±»æ¥æ•è·è¿›åº¦
        class TSNEWithProgress(TSNE):
            def __init__(self, *args, **kwargs):
                self.pbar = None
                super().__init__(*args, **kwargs)
            
            def _gradient_descent(self, *args, **kwargs):
                # åˆ›å»ºè¿›åº¦æ¡
                self.pbar = tqdm(total=self.n_iter, desc="t-SNE Iterations", unit="iter")
                
                # é‡å†™_gradient_descentæ¥æ˜¾ç¤ºè¿›åº¦
                original_method = super()._gradient_descent
                
                def progress_callback(*args, **kwargs):
                    if hasattr(self, '_iter_count'):
                        self._iter_count += 1
                    else:
                        self._iter_count = 1
                    
                    if self.pbar:
                        self.pbar.update(1)
                        self.pbar.set_postfix({
                            'Iter': f"{self._iter_count}/{self.n_iter}",
                            'Status': 'Running'
                        })
                    
                    return original_method(*args, **kwargs)
                
                try:
                    result = original_method(*args, **kwargs)
                    if self.pbar:
                        self.pbar.set_postfix({'Status': 'Completed'})
                        self.pbar.close()
                    return result
                except Exception as e:
                    if self.pbar:
                        self.pbar.close()
                    raise e
        
        try:
            # åˆå§‹åŒ–t-SNE
            tsne = TSNE(
                n_components=2,
                perplexity=perplexity,
                n_iter=n_iter,
                random_state=random_state,
                verbose=0,  # å…³é—­sklearnçš„verboseè¾“å‡º
                init='pca',
                early_exaggeration=12.0,
                learning_rate='auto'
            )
            
            # æ˜¾ç¤ºå¼€å§‹ä¿¡æ¯
            start_time = time.time()
            print(f"   - Input shape: {features.shape}")
            print(f"   - Target perplexity: {perplexity}")
            
            # æ‰§è¡Œt-SNEï¼ˆæ˜¾ç¤ºç®€å•è¿›åº¦ï¼‰
            with tqdm(total=100, desc="t-SNE Progress", unit="%") as pbar:
                pbar.set_description("t-SNE: Initializing")
                pbar.update(5)
                
                pbar.set_description("t-SNE: Computing similarities")
                pbar.update(15)
                
                pbar.set_description("t-SNE: Running optimization")
                reduced_features = tsne.fit_transform(features)
                pbar.update(80)
                
                pbar.set_description("t-SNE: Completed")
                pbar.update(100)
            
            end_time = time.time()
            print(f"âœ… t-SNE completed successfully!")
            print(f"   - Output shape: {reduced_features.shape}")
            print(f"   - Time taken: {end_time - start_time:.2f} seconds")
            
            return reduced_features
            
        except Exception as e:
            print(f"âŒ t-SNE failed: {e}")
            raise

    def perform_dimensionality_reduction(self, features, method='tsne', n_components=2, 
                                       perplexity=30, n_iter=1000, random_state=42):
        """
        æ‰§è¡Œé™ç»´
        
        Args:
            features: ç‰¹å¾çŸ©é˜µ
            method: é™ç»´æ–¹æ³• ('tsne', 'pca', 'pca_tsne')
            n_components: é™ç»´åçš„ç»´åº¦
            perplexity: t-SNEå‚æ•°
            n_iter: t-SNEè¿­ä»£æ¬¡æ•°
            random_state: éšæœºç§å­
        
        Returns:
            reduced_features: é™ç»´åçš„ç‰¹å¾
        """
        print(f"\nğŸš€ Starting dimensionality reduction using {method.upper()}")
        print(f"Input features shape: {features.shape}")
        
        # æ•°æ®é¢„å¤„ç†ï¼šæ ‡å‡†åŒ–
        print("ğŸ“Š Standardizing features...")
        with tqdm(total=100, desc="Standardization", unit="%") as pbar:
            pbar.update(20)
            scaler = StandardScaler()
            pbar.update(40)
            features_scaled = scaler.fit_transform(features)
            pbar.update(40)
        
        print(f"âœ… Standardization completed. Shape: {features_scaled.shape}")
        
        if method == 'pca':
            # ä½¿ç”¨PCAé™ç»´
            reduced_features, pca = self.perform_pca_with_progress(
                features_scaled, n_components, random_state)
            
        elif method == 'pca_tsne':
            # å…ˆç”¨PCAé™ç»´åˆ°50ç»´ï¼Œå†ç”¨t-SNEé™ç»´åˆ°2ç»´
            print("\nğŸ”„ Step 1/2: PCA preprocessing...")
            reduced_features_pca, pca = self.perform_pca_with_progress(
                features_scaled, 50, random_state)
            
            print(f"\nğŸ”„ Step 2/2: t-SNE final reduction...")
            reduced_features = self.perform_tsne_with_progress(
                reduced_features_pca, perplexity, n_iter, random_state)
            
        else:  # method == 'tsne'
            # ç›´æ¥ä½¿ç”¨t-SNE
            reduced_features = self.perform_tsne_with_progress(
                features_scaled, perplexity, n_iter, random_state)
        
        print(f"\nğŸ‰ Dimensionality reduction completed!")
        print(f"Final result shape: {reduced_features.shape}")
        return reduced_features

    def visualize_domain_difference(self, reduced_features, labels, dataset_name, 
                                   method='tsne', save_path=None):
        """
        å¯è§†åŒ–åŸŸå·®å¼‚
        
        Args:
            reduced_features: é™ç»´åçš„ç‰¹å¾
            labels: æ—¶ç›¸æ ‡ç­¾
            dataset_name: æ•°æ®é›†åç§°
            method: é™ç»´æ–¹æ³•åç§°
            save_path: ä¿å­˜è·¯å¾„
        """
        print(f"\nğŸ¨ Creating visualization...")
        
        plt.figure(figsize=(12, 8))
        
        # åˆ†ç¦»æ—¶ç›¸Aå’Œæ—¶ç›¸Bçš„ç‚¹
        phase_A_idx = labels == 0
        phase_B_idx = labels == 1
        
        phase_A_points = reduced_features[phase_A_idx]
        phase_B_points = reduced_features[phase_B_idx]
        
        # ç»˜åˆ¶æ•£ç‚¹å›¾
        plt.scatter(phase_A_points[:, 0], phase_A_points[:, 1], 
                   c='red', alpha=0.6, s=20, label=f'Phase A ({len(phase_A_points)} images)')
        plt.scatter(phase_B_points[:, 0], phase_B_points[:, 1], 
                   c='blue', alpha=0.6, s=20, label=f'Phase B ({len(phase_B_points)} images)')
        
        plt.title(f'Domain Difference Visualization - {dataset_name}\nHRNet Features + {method.upper()}', 
                 fontsize=16, fontweight='bold')
        plt.xlabel(f'{method.upper()} Dimension 1', fontsize=12)
        plt.ylabel(f'{method.upper()} Dimension 2', fontsize=12)
        plt.legend(fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        plt.figtext(0.02, 0.02, 
                   f'Total samples: {len(reduced_features)}\n'
                   f'Phase A: {len(phase_A_points)} | Phase B: {len(phase_B_points)}',
                   fontsize=10, ha='left')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ Visualization saved to: {save_path}")
        
        plt.show()
        print("âœ… Visualization completed!")

    def run_visualization(self, split='train', max_samples=None, batch_size=32, 
                         method='pca_tsne', perplexity=30, save_path=None):
        """
        è¿è¡Œå®Œæ•´çš„å¯è§†åŒ–æµç¨‹
        
        Args:
            split: æ•°æ®é›†åˆ†å‰²
            max_samples: æœ€å¤§æ ·æœ¬æ•°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æ ·æœ¬
            batch_size: æ‰¹å¤„ç†å¤§å°
            method: é™ç»´æ–¹æ³• ('tsne', 'pca', 'pca_tsne')
            perplexity: t-SNEå‚æ•°
            save_path: ä¿å­˜è·¯å¾„
        """
        print("ğŸš€ Starting domain difference visualization...")
        
        # 1. åŠ è½½æ•°æ®é›†è·¯å¾„
        print("\nğŸ“ Step 1/4: Loading dataset paths...")
        image_paths = self.load_dataset_paths(split, max_samples)
        
        # 2. æå–ç‰¹å¾
        print("\nğŸ” Step 2/4: Extracting features...")
        features, labels = self.extract_features(image_paths, batch_size)
        
        # 3. æ‰§è¡Œé™ç»´
        print("\nğŸ“‰ Step 3/4: Performing dimensionality reduction...")
        reduced_features = self.perform_dimensionality_reduction(
            features, method=method, perplexity=perplexity)
        
        # 4. å¯è§†åŒ–ç»“æœ
        print("\nğŸ¨ Step 4/4: Creating visualization...")
        dataset_name = os.path.basename(self.dataset_path)
        self.visualize_domain_difference(reduced_features, labels, dataset_name, 
                                       method, save_path)
        
        print("\nğŸ‰ All steps completed successfully!")
        return reduced_features, labels


def main():
    parser = argparse.ArgumentParser(description='Visualize domain differences in change detection datasets')
    parser.add_argument('--dataset', type=str, required=True, 
                       help='Path to dataset directory')
    parser.add_argument('--split', type=str, default='train', choices=['train', 'val', 'test'],
                       help='Dataset split to use')
    parser.add_argument('--max_samples', type=int, default=None,
                       help='Maximum number of image pairs to process (None for all samples)')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='Batch size for feature extraction')
    parser.add_argument('--method', type=str, default='pca_tsne', 
                       choices=['tsne', 'pca', 'pca_tsne'],
                       help='Dimensionality reduction method')
    parser.add_argument('--perplexity', type=int, default=30,
                       help='t-SNE perplexity parameter')
    parser.add_argument('--save_path', type=str, default=None,
                       help='Path to save the visualization')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
    if not os.path.exists(args.dataset):
        # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        dataset_path = os.path.join(os.environ.get("CDPATH", ""), args.dataset)
        if not os.path.exists(dataset_path):
            raise FileNotFoundError(f"Dataset not found: {args.dataset}")
        args.dataset = dataset_path
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = DomainVisualizer(args.dataset)
    
    # è¿è¡Œå¯è§†åŒ–
    if args.save_path is None:
        dataset_name = os.path.basename(args.dataset)
        if args.max_samples:
            args.save_path = f"{dataset_name}_domain_visualization_{args.method}_{args.max_samples}samples.png"
        else:
            args.save_path = f"{dataset_name}_domain_visualization_{args.method}_all_samples.png"
    
    visualizer.run_visualization(
        split=args.split,
        max_samples=args.max_samples,
        batch_size=args.batch_size,
        method=args.method,
        perplexity=args.perplexity,
        save_path=args.save_path
    )


if __name__ == "__main__":
    main()